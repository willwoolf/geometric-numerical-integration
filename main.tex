\documentclass{report}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}


\newtheorem{theorem}{Theorem}[subsection]
\newtheoremstyle{exampstyle}
  {\topsep} % Space above
  {\topsep} % Space below
  {} % Body font
  {} % Indent amount
  {\bfseries} % Theorem head font
  {.} % Punctuation after theorem head
  {.5em} % Space after theorem head
  {} % Theorem head spec (can be left empty, meaning `normal')
\theoremstyle{exampstyle} \newtheorem{example}[theorem]{Example}
\theoremstyle{exampstyle} \newtheorem{remark}[theorem]{Remark}
\theoremstyle{exampstyle} \newtheorem{definition}[theorem]{Definition}
\theoremstyle{exampstyle} \newtheorem{lemma}[theorem]{Lemma}

\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{float}
\usepackage{dsfont}
\usepackage[width=6in, height=8in]{geometry}
\usepackage{xcolor}

\usepackage[
backend=biber,
natbib=true,
url=false, 
doi=true,
eprint=false
]{biblatex}
\addbibresource{sources.bib}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}

\begin{document}

\chapter{Hamiltonian Mechanics and Symplecticity}

\section{Definitions}

\subsection{Principles of Hamiltonian Mechanics}

The most general way to define a dynamical system is to denote position by the vector $\mathbf{x}$ and express the system as
\begin{equation}
	\mathbf{\dot{x}} = f(\mathbf{x})
	\label{eqn:dyn}
\end{equation}
for an arbitrary function $f$, using dot notation for time derivative.
This can express any dynamical system from reduction to a first order vector equation.

For a Hamiltonian system in one dimension, we denote position by the variable $q$, and momentum by $p$.
The Hamiltonian $H(q,p)$ is a first integral of the system, used to denote the total energy.
In this case, we write the system as
\begin{equation}
	\dfrac{\mathrm{d}}{\mathrm{d}t}\begin{pmatrix}
		q \\
		p
	\end{pmatrix} = \begin{bmatrix}
		\strut 0 & \strut 1 \\
		\strut -1 & \strut 0
	\end{bmatrix}\begin{bmatrix}
	\dfrac{\strut\mathrm{d}H}{\strut\mathrm{d}q} \\
	\dfrac{\strut\mathrm{d}H}{\strut\mathrm{d}p}
	\end{bmatrix}.
\end{equation}
Explicitly this expands as
\begin{align*}
	&\dot{q} = \dfrac{\partial H}{\partial p}
	&
	\dot{p} = \dfrac{-\partial H}{\partial q}&.	
\end{align*}
If we write $\mathbf{x} = (q,p)^\mathrm{T}$ and denote the matrix as $\mathbf{J}$, which we will refer to as the symplectic matrix,
then the statement of a hamiltonian system is of the form 
\begin{equation}
	\mathbf{\dot{x}} = \mathbf{J}\nabla H(\mathbf{x}),
	\label{eqn:hdyn}
\end{equation}
which resembles Equation \ref{eqn:dyn}.

For an $n$-dimensional problem,
we instead denote the variables $q_1, \mathellipsis, q_n, p_1, \mathellipsis, p_n$ as the position and momentum in the directions of each basis vector respectively.
Write $\mathbf{x} = (q_1, \mathellipsis, q_n, p_1, \mathellipsis, p_n)$.
Define $\mathbf{J}$ to be
\begin{equation}
	\mathbf{J} = \begin{bmatrix}
		\mathbf{0}_n & \mathbf{I}_n \\
		-\mathbf{I}_n & \mathbf{0}_n
	\end{bmatrix}
\end{equation}
and the problem can be written as $\mathbf{\dot{x}} = \mathbf{J}\nabla H(\mathbf{x})$.

Define the flow $\varphi_t$ as a map of the problem from an initial time to the time $t$.
Specifically, we write $\varphi_t(\alpha) = \mathbf{x}(t)$ given the initial condition $\mathbf{x}(t=0) = \alpha$. Hence the flow $\varphi_t:\mathds{R}^{2n}\rightarrow \mathds{R}^{2n}$ is a map from the initial point of the system to the time $t$.

The Jacobian matrix $\varphi'_t(\mathbf{\alpha})$ is often called the sensitivity of the flow.
Note that it is the derivative on the initial condition $\mathbf{\alpha}$.
We show the element-wise expression:
\begin{align*}
	\left. \varphi'_t(\alpha) \right)_i &= \left. \frac{\partial}{\partial \alpha} \varphi_t(\alpha) \right)_i \\
	&= \frac{\partial}{\partial \alpha} x_i(t) \\
	&= \begin{bmatrix}
		\frac{\partial x_i}{\partial \alpha_1}, & \mathellipsis, & \frac{\partial x_i}{\partial \alpha_{2n}}
	\end{bmatrix},
\end{align*}
which is the Jacobian.
A flow is symplectic if it satisfies $\varphi'_t(\alpha)^\mathrm{T} \mathbf{J} \varphi'_t(\alpha) = \mathbf{J}.$
The flow of a Hamiltonian system is, by definition, symplectic. We will show this later.
We are concerned with numerical integration techniques which are symplectic.

\subsection{Properties of the flow}

The flow map $\varphi_t: \mathbf{x}_0 \rightarrow \mathbf{x}(t)$ gives us powerful insights into the behaviour of Hamiltonian integration.
We will show expressions for the time derivatives of $\varphi_t(\alpha)$ and $\varphi'_t(\alpha)$.
Starting with the flow, its time derivative is
\begin{align*}
	\frac{\mathrm{d}}{\mathrm{d}t} \left( \varphi_t(\mathbf{x}_0) \right) &= \frac{\mathrm{d}}{\mathrm{d}t} \mathbf{x}(t) \\
	&= \dot{\mathbf{x}}(t) \\
	&= \mathbf{J}\nabla H(\mathbf{x}(t)) \\
	&= \mathbf{J}\nabla H \left( \varphi_t(\mathbf{x}_0) \right).
\end{align*}
We have a similar form for the time derivative of the sensitivity:
\begin{align*}
	\frac{\mathrm{d}}{\mathrm{d}t} \left( \varphi'_t(\mathbf{x}_0) \right) &= \frac{\partial}{\partial \mathbf{x}_0} \frac{\mathrm{d}}{\mathrm{d}t} \varphi_t(\mathbf{x}_0) \\
	&= \frac{\partial}{\partial \mathbf{x}_0} \frac{\mathrm{d}}{\mathrm{d}t} \mathbf{x}(t) \\
	&= \frac{\partial}{\partial \mathbf{x}_0} \dot{\mathbf{x}}(t) \\
	&= \frac{\partial}{\partial \mathbf{x}_0} \mathbf{J}\nabla H(\mathbf{x}(t)) \\
	&= J \nabla^2 H(\mathbf{x}(t)) \left(\frac{\partial}{\partial \mathbf{x}_0} \mathbf{x}(t)\right) \\
	&= J \nabla^2 H(\varphi_t(\mathbf{x}_0))\varphi'_t(\mathbf{x}_0).
\end{align*}
These results will be useful later, when we look at properties of Hamiltonian systems.

\subsection{Methods}
% use this section freely to add methods that need to be referred to

We will explore a selection of methods in this project,
which require an understanding of basic methods from which they develop from.
Assume we have a dynamical system given by Equation \ref{eqn:dyn}.

The explicit (forward) Euler method:
\begin{equation}
	x_{n+1} = x_n + h J \nabla H(x_n).
\end{equation}

The implicit (backward) Euler method:
\begin{equation}
	x_{n+1} = x_n + h J \nabla H(x_{n+1}).
\end{equation}

The implicit midpoint method:
\begin{equation}
	x_{n+1} = x_n + h J \nabla H \left( \frac{x_n + x_{n+1}}{2} \right).
\end{equation}

The trapezium method:
\begin{equation}
	x_{n+1} = x_n + h \left( \frac{J \nabla H(x_n) + J \nabla H(x_{n+1})}{2} \right).
\end{equation}

\section{Examples}
\subsection{Forward Euler Method - Simple Harmonic Oscillator}

If a problem has a closed-form solution, then we can find an explicit expression for the flow.
However, many problems must instead be solved numerically, often using a finite difference method.
We will focus on symplectic and non-symplectic methods for solving differential equations.
If a numerical method maintains symplecticity, it is a symplectic integrator.
These are a class of geometric numerical integrators.

Given an ODE $\dot{\mathbf{x}} = f(\mathbf{x})$, a numerical method is an iteration of the form $\mathbf{x}_{n+1} = \mathbf{x}_n + F(t_n, \mathbf{x}_n; h)$
We can write a step as the map $\Phi: \mathbf{x}_n \rightarrow \mathbf{x}_{n+1}$. The map $\Phi$ is the numerical flow:
rather than mapping from the initial condition to a point at time $t$, we map the solution from one point $t_n$ to the next in a discretised time interval.

Consider the forward Euler method: for $\dot{\mathbf{x}} = f(\mathbf{x})$, the iteration is $\mathbf{x}_{n+1} = \mathbf{x}_n + hf(\mathbf{x}_n)$.
We can apply the Euler method to examples in order to evaluate its properties.

First, we look at the simple harmonic oscillator $m \ddot{x} = -k x$.
In Hamiltonian variables this is
\begin{equation*}
	\begin{aligned}
		&\dot{q} = \frac{p}{m}, &\dot{p} = m\ddot{q} = -kq.
	\end{aligned}
\end{equation*}
A suitable Hamiltonian is
\begin{equation*}
	H = \frac{1}{2m}p^2 + \frac{1}{2}kq^2.
\end{equation*}
Applying the forward Euler method to the problem, we get
\begin{equation*}
	\begin{aligned}
		q_{n+1} &= q_n + h\frac{\partial H}{\partial p}(q_n, p_n) &= q_n + \frac{p_n}{m}\\
		p_{n+1} &= p_n - h\frac{\partial H}{\partial q}(q_n, p_n) &= p_n - kq_n
	\end{aligned}
\end{equation*}
which can be written as a matrix equation
\begin{equation*}
	\begin{pmatrix}
		q_{n+1} \\
		p_{n+1}
	\end{pmatrix} = \begin{bmatrix}
		1 & 1/m \\
		-k & 1
	\end{bmatrix} \begin{pmatrix}
		q_n \\
		p_n
	\end{pmatrix}.
\end{equation*}
where the matrix is the numerical flow map.
We could show that this matrix does not satisfy the symplectic identity,
but it is enough to show that its determinant is clearly not equal to $1$, which is necessary for symplectic matrices.

\subsection{Example of a symplectic flow}
We can demonstrate symplecticity with the actual flow map. Note the general closed form solution:
\begin{equation*}
	\begin{aligned}
		q(t) &= A\cos\left( \sqrt{\frac{k}{m}} t \right) + B \sin\left( \sqrt{\frac{k}{m}}t \right) \\
		p(t) &= B\sqrt{km} \cos\left( \sqrt{\frac{k}{m}} t \right) -A\sqrt{km} \sin\left( \sqrt{\frac{k}{m}}t \right) 
	\end{aligned}
\end{equation*}
for arbitrary constants $A$ and $B$.
Impose initial conditions:
suppose $q(t=0) = q_0,~ p(t=0) = p_0.$
Define $\omega = \sqrt{k/m}$ for shorthand, and apply the initial conditions to find that the coefficients are $A = q_0,~ B = p_0/m \omega$
Hence the particular solution is
\begin{equation*}
	\begin{aligned}
		q(t) &= q_0 \cos\left( \omega t \right) + \frac{p_0}{m\omega} \sin\left( \omega t \right) \\
		p(t) &= p_0 \cos\left( \omega t \right) - q_0 m\omega \sin\left( \omega t \right).
	\end{aligned}
\end{equation*}
We are in the position to evaluate the Jacobian entry-wise.
\begin{equation*}
	\varphi'_t \begin{pmatrix}
		q_0 \\
		p_0
	\end{pmatrix} = \begin{bmatrix}
		\frac{\partial q}{\partial q_0} & \frac{\partial q}{\partial p_0} \\
		\frac{\partial p}{\partial q_0} & \frac{\partial p}{\partial p_0}
	\end{bmatrix} = \begin{bmatrix}
		\cos(\omega t) & \frac{1}{m\omega} \sin(\omega t) \\
		-m\omega \sin(\omega t) & \cos(\omega t)
	\end{bmatrix},
\end{equation*}
and if we now plug this into the symplectic identity we get
\begin{align*}
	\varphi'_t(x_0)^\mathrm{T} \mathbf{J} \varphi'_t(x_0) &= \begin{bmatrix}
		\cos(\omega t) & -m\omega \sin(\omega t) \\
		\frac{1}{m\omega} \sin(\omega t) & \cos(\omega t)
	\end{bmatrix} \begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix} \begin{bmatrix}
		\cos(\omega t) & \frac{1}{m\omega} \sin(\omega t) \\
		-m\omega \sin(\omega t) & \cos(\omega t)
	\end{bmatrix} \\
	&= \begin{bmatrix}
		m \omega \sin(\omega t) & \cos(\omega t) \\
		-\cos(\omega t) & \frac{1}{m \omega} \sin(\omega t)
	\end{bmatrix} \begin{bmatrix}
		\cos(\omega t) & \frac{1}{m\omega} \sin(\omega t) \\
		-m\omega \sin(\omega t) & \cos(\omega t)
	\end{bmatrix} \\
	&= \begin{bmatrix}
		m \omega \sin(\omega t) \cos(\omega t) - m \omega \sin(\omega t) \cos(\omega t)  & \sin^2(\omega t) + \cos^2(\omega t) \\
		-\cos^2(\omega t) - \sin^2(\omega t) & -\frac{1}{m\omega}\cos(\omega t)\sin(\omega t) + \frac{1}{m \omega}\cos(\omega t)\sin(\omega t)
	\end{bmatrix} \\
	&= \begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix} = \mathbf{J}.
\end{align*}
Hence the flow is symplectic.

\subsection{A symplectic integrator}
With symplectic integration, we are interested in numerical methods for which the numerical flow also attains symplecticity.
One such example is the symplectic Euler method
\begin{equation*}
	\begin{pmatrix}
		q_{n+1} \\
		p_{n+1} 
	\end{pmatrix} = \begin{pmatrix}
		q_{n} \\
		p_{n}
	\end{pmatrix} + h \nabla H(q_{n}, p_{n+1}).
\end{equation*}
For an arbitrary problem this method is implicit. However, many problems have a separate Hamiltonian that allows the iteration to be performed in two explicit steps. 
The simple harmonic oscillator has a Hamiltonian $H(q, p) = \frac{1}{2m}p^2 + \frac{1}{2}kq^2$ which can be written as $H(q, p) = V(q) + T(p)$, where $V(q)$ represents kinetic energy and $T(p)$ represents potential energy of the system.
We expand out the method as
\begin{equation*}
	\begin{pmatrix}
		q_{n+1} \\
		p_{n+1} 
	\end{pmatrix} = \begin{pmatrix}
		q_{n} \\
		p_{n}
	\end{pmatrix} + h \mathbf{J} \begin{pmatrix}
		V'(q_n) \\
		T'(p_{n+1})
	\end{pmatrix} = \begin{pmatrix}
		q_{n} + \frac{h}{m}p_{n+1} \\
		p_{n} - hk q_n
	\end{pmatrix}.
\end{equation*}
On inspection, we can perform this iteration separably: compute $p_{n+1}$ using $p_n$ and $q_n$,
then use $q_n$ and $p_{n+1}$ to compute $q_{n+1}$.
Important to note is that this is specifically the symplectic Euler-VT method, since we evaluate $V'$ and then $T'$,
and the symplectic Euler-TV method is an alternative which computes in the opposite order analogously.
This is of course assuming that the Hamiltonian is separable, which it may not be.
For simplicity we will stick with the VT method for examples.
We find an expression for the numerical flow:
\begin{equation*}
	\begin{aligned}
		\begin{pmatrix}
			q_{n+1} \\
			p_{n+1} 
		\end{pmatrix} &= \begin{pmatrix}
			q_{n} + \frac{h}{m} \left( p_{n} - h \omega q_n \right) \\
			p_{n} - h \omega q_n
		\end{pmatrix} \\
		&= \begin{bmatrix}
			1 - \frac{h^2 k}{m} & \frac{h}{m} \\
			-hk & 1
		\end{bmatrix} \begin{pmatrix}
			q_n \\
			p_n
		\end{pmatrix} \equiv \Phi_h \begin{pmatrix}
			q_n \\
			p_n
		\end{pmatrix}
	\end{aligned}
\end{equation*}
and just like before, test the symplectic identity
\begin{equation*}
	\Phi^\mathrm{T}\mathbf{J}\Phi = \begin{bmatrix}
		\left(1-\frac{h^2 k}{m}\right)(-hk) + \left(\frac{h^2 k}{m}-1\right)(-hk) & 1 - \frac{h^2 k}{m} + \frac{h^2 k}{m} \\
		-\frac{h^2 k}{m} + \frac{h^2 k}{m} -1 & \frac{h}{m} - \frac{h}{m}
	\end{bmatrix} = \begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix} = \mathbf{J}.
\end{equation*}
Hence this method is symplectic for this example.

\subsection{The Simple Pendulum}

%figure on comparison of three methods

The simple pendulum is the one-dimensional system defined by
\begin{equation*}
	ml\frac{\mathrm{d}^2 \theta}{\mathrm{d}t^2} = - mg \sin(\theta)'
\end{equation*}
For this problem, we define $q = \theta$, $p = \dot{\theta}$ and the Hamiltonian
\begin{equation*}
	H(q,p) = \frac{1}{2}p^2 + k^2(1-\cos(q))
\end{equation*}
where $k^2 = g/l$.
This Hamiltonian can be obtained by integrating the system, and is therefore a conserved quantity.
We will look at a selection of numerical methods applied to this problem.
Recall Euler's method, of the form $x_{n+1} = x_n + h \mathbf{J} \nabla H(x_n)$. This expands to:
\begin{equation*}
	\begin{pmatrix}
		q_{n+1} \\
		p_{n+1}
	\end{pmatrix}^E = \begin{pmatrix}
		q_n \\
		p_n
	\end{pmatrix} + h \begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix} \begin{pmatrix}
		k^2 \sin(q_n) \\
		p_n
	\end{pmatrix} = \begin{pmatrix}
		q_n + h p_n \\
		p_n - h k^2 \sin(q_n)
	\end{pmatrix}.
\end{equation*}
The Implicit Midpoint method gives us
\begin{equation*}
	\begin{pmatrix}
		q_{n+1} \\
		p_{n+1}
	\end{pmatrix}^M = \begin{pmatrix}
		q_n \\
		p_n
	\end{pmatrix} + h \begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix} \begin{pmatrix}
		k^2 \sin \left(\dfrac{q_n + q_{n+1}}{2}\right) \\
		\dfrac{p_n + p_{n+1}}{2}
	\end{pmatrix} = \begin{pmatrix}
		q_n + h \left( \dfrac{p_n + p_{n+1}}{2} \right) \\
		p_n - h k^2 \sin \left( \frac{q_n + q_{n+1}}{2} \right)
	\end{pmatrix}.
\end{equation*}
Finally, applying the Symplectic Euler-VT method yields
\begin{equation}
	\begin{pmatrix}
		q_{n+1} \\
		p_{n+1}
	\end{pmatrix}^S = \begin{pmatrix}
		q_n \\
		p_n
	\end{pmatrix} + h \begin{bmatrix}
		0 & 1 \\
		-1 & 0
	\end{bmatrix} \begin{pmatrix}
		k^2 \sin(q_n) \\
		p_{n+1}
	\end{pmatrix} = \begin{pmatrix}
		q_n + h p_{n+1} \\
		p_n - h k^2 \sin(q_n)
	\end{pmatrix}
\end{equation}

\section{Symplecticity of a Hamiltonian System}

\subsection{Hamiltonian Systems are Symplectic}

Earlier, we looked at the symplecticity of the flow of a particular Hamiltonian system.
We will now generalise this result to any Hamiltonian system.
It should be noted that the symplecticity of the flow is equivalent to the system itself being Hamiltonian.

\begin{theorem}
\label{thm:hamil}
A dynamical system is Hamiltonian if and only if its flow is symplectic.
\end{theorem}
\begin{proof}
$(\Rightarrow)$ Consider the flow of a Hamiltonian system at time $t=0$. By definition, $\varphi_t(x_0) = x(t)$ given $x(0) = x_0$,
therefore $\varphi_0(x_0) = x_0$. Hence the sensitivity at $t=0$ is $\varphi'_0(x_0) = I$ the identity matrix.
The symplectic identity is satisfied trivially: $(\varphi'_0(x_0))^\mathrm{T} J \varphi'_0(x_0) = IJI = J$.

Now, instead of finding an expression of the symplectic identity at time $t$,
we show that this quantity is unchanging in time.
By differentiating, the expression distributes by the product rule:
\begin{equation*}
	\frac{\mathrm{d}}{\mathrm{d}t} \left(
		\varphi'_t(x_0)^\mathrm{T} J \varphi'_t(x_0)
	\right) = \left(
		\frac{\mathrm{d}}{\mathrm{d}t} \varphi'_t(x_0)^\mathrm{T}
	\right) J \varphi'_t(x_0) + \varphi'_t(x_0)^\mathrm{T} J \left(
		\frac{\mathrm{d}}{\mathrm{d}t} \varphi'_t(x_0)
	\right).
\end{equation*}
We can find an expression for the derivative term:
\begin{align*}
	\frac{\mathrm{d}}{\mathrm{d}t} \varphi'_t(x_0) &= \frac{\mathrm{d}}{\mathrm{d}t} J \nabla H(\varphi_t(x_0)) \\
	&= J \nabla^2 H(\varphi_t(x_0)) \varphi'_t(x_0).
\end{align*}
Now plug this back in, becoming
\begin{align*}
	\frac{\mathrm{d}}{\mathrm{d}t} \left(
		\varphi'_t(x_0)^\mathrm{T} J \varphi'_t(x_0)
	\right) &= \left( J \nabla^2 H(\varphi_t)\varphi'_t \right)^\mathrm{T} J \varphi'_t 
	+ \varphi'_t J \left( 
		J \nabla^2 H(\varphi_t) \varphi'_t
  	\right) \\
	&= (\varphi'_t)^\mathrm{T} \nabla^2 H(\varphi_t)^\mathrm{T} J^\mathrm{T} J \varphi'_t
	+ (\varphi'_t)^\mathrm{T} J^2 \nabla^2 H(\varphi_t) \varphi'_t(x_0) \\
	&= (\varphi'_t)^\mathrm{T} \nabla^2 H(\varphi_t)^\mathrm{T} \varphi'_t - (\varphi'_t)^\mathrm{T} \nabla^2 H(\varphi_t) \varphi'_t
\end{align*}
since $J^\mathrm{T}J = I$ and $J^2 = -I$.
Under the assumption that the Hessian matrix $\nabla^2 H(\varphi_t)$ is symmetric,
this expression evaluates to zero and hence the symplectic identity is satisfied for all $t$ and we are done.

$(\Leftarrow)$ Assuming that the sensitivity satisfies the symplectic identity, we want to show that the system is Hamiltonian.
% INCOMPLETE. TODO: either formalise a proof OR cite one

\end{proof}

\section{Numerical and Symplectic Integrators}

\subsection{Forming Methods}
It is important to note at the moment that the only example we have looked at is the simple harmonic oscillator, which has a closed form solution.
Our results so far only serve for understanding the definition of symplecticity.
Further on we will discuss and explore real applications of symplectic methods.
% go into more detail of forward euler

In contrast to our examples so far, we usually solve an ODE numerically when we cannot find a closed form solution, and we want to produce a numerical approximation with which we can analyse its behaviour.
However, numerical integrators such as the forward Euler method do not always provide reliable solutions to the problems given.
In oder to explore this further, we need to introduce the concept of A-stability.

Consider the linear test problem $\dot{x} = \lambda x$. Given an initial condition $x(t=0) = x_0$, $x$ decays to $0$ as $t \rightarrow \infty$ if $\lambda$ is negative.
Now consider how the forward Euler approximation behaves.
We have the iteration $x_{n+1} = x_n + hf(x_n) = x_n + h(\lambda x_n) = (1 + h\lambda)x_n$.
Hence, given an initial condition, $x_n = (1 + h\lambda)^n x_0$, which decays to zero if $|1+h\lambda| < 1$.
Even if $\lambda < 0$, we can choose values of $h$ for which the sequence does not converge to zero.
A numerical method is called A-stable if, when applied to the linear test problem, the sequence converges to zero for all $h\lambda$ such that $\operatorname{Re}(h\lambda) < 0$.
Euler's method is not A-stable, making it susceptible to long timespan error growth.

We will look at the concept of the adjoint method. Given a method defined by a numerical flow $\Psi_h$,
the adjoint $\Psi^*_h$ is the method that satisfies $\Psi^*_{-h} = \Psi^{-1}_h$.
In words, stepping backward with the adjoint method is equivalent to stepping forward with the inverse.
Adjoint methods are very useful. Given an arbitrary method $\Psi_h$,
the method $\Psi_{h/2} \circ \Psi_{h/2}^*$ is symmetric.
A symmetric method is a method that satisfies $\Psi_h^{-1} = \Psi_{-h}$.
This means if we integrate forwards in time by a particular step, and then integrate back,
we return to the original value since we are equivalently applying the inverse.

We can show that the implicit Euler method is the adjoint of explicit Euler.
First, let $\Psi_h^I$ denote the implicit method and let $\Psi_h^E$ denote the explicit method.
We want to show that $\Psi_h^E = (\Psi_{-h}^I)^{-1}$.
This is equivalent to $\Psi_{-h}^I \circ \Psi_h^E (x) = x$.
If we expand this composition, we obtain
\begin{align*}
	\Phi_{-h}^I \left( \Phi_j^E  (x) \right) &= \Phi_{-h}^I \left( x + h f(x) \right) \\
	&= x + h f(x) - h f\left( \Phi_{-h}^I \left( x + h f(x) \right) \right) \\
	&= x + h f(x) - h f\left( \Phi_{-h}^I \left( \Phi_h^E (x) \right) \right),
\end{align*}
and $\Phi_{-h}^I (\Phi_h^E (x)) = x$ solves this equation. Hence $(\Phi_{-h}^I)^{-1} = \Phi_h^E$.
Note that the explicit and implicit Euler methods cannot be symmetric because they are adjoint.

Other methods of note are the implicit midpoint method and the trapezium method. Implicit midpoint is the method
\begin{equation*}
	\Phi_h^M (x_n) = x_{n+1} = x_n + hf\left(\frac{x_n + x_{n+1}}{2}\right).
\end{equation*}
The trapezium method is similar:
\begin{equation*}
	\Phi_j^T (x_n) = x_{n+1} = x_n + h \left(\frac{f(x_n) + f(x_{n+1})}{2}\right)
\end{equation*}
The implicit midpoint method is symplectic, but the trapezium method is not.
However, it can be shown that these are conjugate methods, meaning that they exhibit similar long-term behaviour.
Two methods $\Psi_h, \Phi_h$ are conjugate if there exists a map $\chi$ such that $\Phi_h = \chi^{-1} \Psi_h \chi$.
Consider applying a method $\Phi_h$ $N$ times. Conjugacy shows that
\begin{align*}
	\left(\Phi_h\right)^N &= \left(\chi^{-1} \Psi_h \chi\right)^N \\
	&= \underbrace{\left(\chi^{-1} \Psi_h \chi \right)\left(\chi^{-1} \Psi_h \chi \right) \mathellipsis \left(\chi^{-1} \Psi_h \chi\right)}_{N} \\
	&= \chi^{-1} (\Psi_h)^N \chi.
\end{align*}
Therefore, conjugate methods remain separated by the conjugacy map $\chi$ for an arbitrary number of iterations.
%% find a defined inverse so that we can show conjugacy.

Earlier, we looked at the Symplectic Euler method, which is a modification of the Euler methods for Hamiltonian integration.
If the Hamiltonian is separable such that $H(q,p) = V(q) + T(p)$, then the Symplectic Euler method is explicit.
This is because in the Symplectic Euler-VT step, we use $p_n$ and $q_n$ to compute $p_{n+1}$, then use $p_{n+1}$ and $q_n$ to compute $q_{n+1}$.
This is exactly the method we applied in our earlier example introducing the Symplectic Euler method.
However, the Symplectic Euler method is generally implicit because a given Hamiltonian for a problem may not be separable.
Denote the Symplectic Euler step by $\Psi_h$. The \textit{St\"{o}rmer-Verlet} method is defined by the step $\Psi_{h/2}^* \circ \Psi_{h/2}$.
Formally, this is
\begin{align*}
	p_{n+\frac{1}{2}} &= p_n - \frac{h}{2}\nabla_q H(q_n, p_{n+\frac{1}{2}}) \\
	q_{n+1} &= \frac{h}{2}\left( \nabla_q H(q_n, p_{n+\frac{1}{2}}) + \nabla_p H(q_{n+1}, p_{n+\frac{1}{2}}) \right) \\
	p_{n+1} &= p_{n+\frac{1}{2}} - \frac{h}{2} \nabla_q H(q_{n+1}m p_{n+\frac{1}{2}}).
\end{align*}

There are several properties of symplectic methods we have not talked about, which may be of interest now.
We have not shown that ($1$) the adjoint of a symplectic method is symplectic, and ($2$) the composition of symplectic methods is symplectic.
These are relatively simple properties which can be proven from the defintions, but it will help our understanding to cover these.
First of all, the definition of the adjoint method states $\Phi^*_h = \Phi^{-1}_{-h}$.
By algebraic manipulation,
\begin{align*}
	\Phi_h^\intercal J \Phi_h &= J \\
	\Rightarrow \Phi_{-h}^\intercal J \Phi_{-h} &= J \\
	\Rightarrow J &= (\Phi_{-h}^{-1})^\intercal J (\Phi_{-h}^{-1}) = (\Phi_h^*)^\intercal J (\Phi_h^*)
\end{align*}
and so clearly the adjoint is symplectic.
The composition of symplectic maps is done similarly. Denote two symplectic maps $\Phi_h, \Psi_h$. Then
\begin{align*}
	\left(\Phi_h \Psi_h\right)^\intercal J \left(\Phi_h \Psi_h\right) &= \Psi_h^\intercal \Phi_h^\intercal J \Phi_h \Psi_h \\
	&= \Psi_h^\intercal J \Psi_h \\
	&= J.
\end{align*}
Therefore the composition of symplectic maps is symplectic.
In covering both of these properties, we can be certain that the St\"{o}rmer-Verlet method is in fact symplectic.

\subsection{Symplectic Integration}

% properties required for A-stability
% properties required for symplecticity
Symplecticity and A-stability are not linked in a sense that one implies the other, but they are similar in how both properties to provide well-behaved solutions for long timespan integrations.
The formal definition is that a symplectic integration method maintains the form $\mathrm{d}q_i \wedge \mathrm{d}p_i$ with $i = 1, \mathellipsis, n$ for an $n$-dimensional problem.
The form is an infinitesimal area generated by the infinitesimals in $q, p$.
For a one-dimensional problem, we can produce the phase portrait by plotting $p$ against $q$.
A single point in the phase portrait represents the state of the dynamical system at a fixed point in time.
The flow and the numerical flow are maps between points in the phase portrait.
If we think of the phase portrait as a solution space for a one-dimensional dynamical system, we can say that symplectic methods preserve the area of the solution space.
This is the paradigm of symplectic integration: by maintaining area of the phase space under mapping of the numerical flow, we maintain qualitative behaviour of the ODE over long timespans.
Furthermore, the conservation of area is equivalent to a symplectic method maintaining a first integral of the system, which is the Hamiltonian $H$.

The dilemma with symplectic integration is that it can be an extremely expensive implementation, when another method might suffice.
For applications in celestial mechanics, symplectic integrators are extremely important, since we may need to estimate the motion of celestial bodies far into the future, to a required accuracy.
However, many examples would be exhaustive for symplectic methods, since it would be more computationally efficient to use an error-controlled explicit integrator.
In this case, we accrue error over time, but we can make a restriction of the local error in order to keep the global error below a particular threshold.
An extremely popular family of integrators would be the explicit Runge-Kutta methods.

\subsection{Runge-Kutta Methods}

These are methods of the form
\begin{equation*}
	x_{n+1} = x_n + h(\sum_{i = 1}^{s} b_i k_i )
\end{equation*}
where
\begin{equation*}
	k_i = f(t_n + c_i h,~ x_n + h\sum_{j = 1}^{s} a_{ij}k_j).	
\end{equation*}
An explicit Runge Kutta method is a sequence of explicit steps to gain a better approximation.
We aim to choose the parameters such that we can reduce the order of the error for each step.
For ease of notation, we introduce the Butcher tableau for a Runge Kutta method
\begin{equation*}
	\begin{array}{c|ccc}
		c_1  &a_{11} &\dots &a_{1s} \\
		\vdots &\vdots & &\vdots \\
		c_s &a_{s1} &\dots &a_{ss} \\
		\hline
		&b_1 &\dots &b_s
	\end{array}
\end{equation*}
which also helps us regard the Runge Kutta method as defined by vectors and a matrix.

Consider the linear test problem $\dot{x} = \lambda x$.
We have already explored stability for the basic Euler methods.
We will look at an explicit 3-stage method.
First, find expressions for the $k_i$:
\begin{align*}
	k_1 &= \lambda x_n, \\
	k_2 &= \lambda\left( x_n + h a_{21}k_1 \right) \\
	&= \left( \lambda + h a_{21}\lambda^2 \right)x_n, \\
	k_3 &= \lambda \left( x_n + h a_{31}k_1 + h a_{32}k_2 \right) \\
	&= \lambda \left( x_n + h a_{31} \lambda x_n + h a_{32}\left( \lambda + h a_{21} \lambda^2 \right) x_n \right) \\
	&= \left( \lambda + h a_{31}\lambda^2 + h a_{32}\lambda^2 + h^2 a_{32}a_{21}\lambda^3 \right) x_n.
\end{align*}
therefore
\begin{align*}
	x_{n+1} &= x_n + h \left( b_1 k_1 + b_2 k_2 + b_3 k_3 \right) \\
	&= x_n + h b_1 \lambda x_n + h b_2 \left(\lambda + h a_{21} \lambda^2\right)x_n + hb_3 \left( \lambda + h a_{31} \lambda^2 + h a_{32} \lambda ^2 + h^2 a_{32} a_{21} \lambda^3\right)x_n \\
	&= \left(
		1 + \left( b_1 + b_2 + b_3 \right) h\lambda + \left(
			b_2 a_{21} + b_3 (a_{31} + a_{32})
		\right)h^2\lambda^2 + \left(
			b_3 a_{32} a_{21}
		\right)h^3\lambda^3
	\right)x_n.
\end{align*}
This coefficient term is a polynomial on $h\lambda$, which we denote by $R(h\lambda)$.
For any explicit $k$-stage Runge-Kutta method the stability function is a polynomial.
To ensure A-stability, we require that $|R(h\lambda)| < 0$ for $h \lambda$ in the left half of the complex plane.
For any explicit method, the stability function is a polynomial.
For any polynomial $p(y)$, we diverge to infinity as $|y| \rightarrow \infty$.
Hence it is impossible for any explicit Runge-Kutta method to be A-stable.

In general, the stability function for a Runge-Kutta method is
\begin{equation*}
	r(\lambda) = \frac{\det(I - \lambda A + \lambda eb^\mathrm{T})}{\det(I - \lambda A)}
\end{equation*} %% cite this result
where $A = (a_{ij})$, $b = (b_i)$ and $e$ is the vector of all ones.
The stability function is a rational function in all cases.

It is impossible for explicit RK methods to be A-stable, because the stability functions are polynomials which diverge to infinity as $|h\lambda| \rightarrow \infty$.
A general Runge-Kutta method is A-stable if $r(\lambda) < 0$ for all $\lambda < 0$.
%% more stuff go here


\subsection{Symplectic RK Methods}

We have shown that all A-stable Runge-Kutta methods are necessarily implicit.
This is also the case for all symplectic Runge-Kutta methods.

\begin{theorem}
\label{thm:symrk}
If a Runge-Kutta method satisfies
\begin{equation}
	b_i a_{ij} + b_j a_{ji} - b_ b_j = 0
\end{equation}
for all $i, j = 1, \mathellipsis, s$ then it is symplectic.
\end{theorem}
\begin{proof}

This proof is in two parts. First, we want to show that any Runge-Kutta method must satisfy this rule in order to preserve quadratic invariants of the system.
Then, we show that any Runge-Kutta method which preserves these invariants is in fact symplectic.

\textit{Part I:}
Start by considering the recurrence $x_1 = x_0 + h \sum_{j=1}^{s} b_i k_i$ and let $C$ be an arbitrary matrix, in which case we can express a quadratic as
\begin{equation}
	x_1^\intercal C x_1 = x_0^\intercal C x_0 + h \sum_{i=1}^{s} b_i k_i^\intercal C x_0 + h \sum_{j=1}^{s} b_j x_0^\intercal C k_j + h^2 \sum_{i=1}^{s} \sum_{j=1}^{s} b_i b_j k_i^\intercal C k_j
\end{equation}
by expanding. We can make a simplification by writing $k_i = f(X_i) = f\left(x_0 h \sum_{j=1}^{s}a_{ij}k_j\right)$, which is the definition of the $k_i$ evaluations.
The $f$ is the function which defines the dynamical system.
Our expansion becomes
\begin{equation} %TODO: expanantion of the expansion here
	x_1^\intercal C x_1 = x_0^\intercal C x_0 + 2h \sum_{i=1}^{s} b_i X_i^\intercal C f(X_i) + h^2 \sum_{i=1}^{s} \sum_{j=1}^{s} (b_i b_j - b_i a_{ij} - b_j a_{ji}k_i^\intercal C k_j).
\end{equation}
We can notice that the $x^\intercal C f(x)$ is the application of product rule differentiation, namely that
\begin{equation*}
	x^\intercal C f(x) = \frac{1}{2} \left(\frac{\mathrm{d}}{\mathrm{d}t} (x^\intercal C x) \right)
\end{equation*}
and this is a derivative of a quadratic term.
% explain why these terms should change
Therefore we require $b_i b_j - b_i a_{ij} - b_j a_{ji} = 0$ in order for the method to preserve quadratic invariants.

\textit{Part II:}
Our dynamical system is defined as $\dot{x} = f(x)$ with the initial condition $x(0) = x_0$.
If we differentiate this problem with respect to $x_0$, we obtain
\begin{align*}
	\frac{\mathrm{d}}{\mathrm{d}t} \varphi'_t(x_0) &= f'(\varphi_t(x_0))\varphi'_t(x_0), \\
	\varphi'_0(x_0) &= I
\end{align*}
This is similar to when we looked at demonstrating symplecticity of a regular Hamiltonian system.
Clearly $\varphi'_0(x_0)^\intercal J \varphi'_0(x_0) = IJI = J$.
If we differentiate $\varphi'_t(x_0)^\intercal J \varphi'_t(x_0)$ with respect to time, the expression reduces to zero.
We already showed this when we showed that the flow of a Hamiltonian system is symplectic.
Therefore, this expression is a first integral of the system.
Since it is quadratic in $\varphi'_t(x_0)$, it will be conserved by the Runge-Kutta methods which satisfy the property that $b_i b_j - b_i a_{ij} - b_j a_{ji} = 0$.
Therefore the symplectic identity is a quadratic first integral of the system, and hence these Runge-Kutta methods are symplectic.
% one theorem is that if the method satisfies the implicit criterion then it preserves quadratic integrals
% another result shows that RK methods that preserve quadratic integrals are symplectic

\end{proof}

If we solve a dynamical system $\dot{x} = f(x)$ using a symplectic Runge-Kutta method, we get a numerical flow map $\varPhi_h(x_0)$.
We can differentiate this with respect to the intial condition $x_0$ to obtain a sensitivity of the numerical flow $\varPhi'_h(x_0)$.
However, this sensitivity matrix is equivalent to the numerical flow map obtained by applying a symplectic Runge-Kutta method to $\frac{\mathrm{d}}{\mathrm{d}t}\varphi'_t(x_0) = f'(\varphi_t(x_0))\varphi'_t(x_0)$,
which is our dynamical system differentiated with respect to the initial condition. The operations are commutative.
We will prove this in the following:

\begin{theorem}
\label{thm:commt}
	For a dynamical system $\dot{x} = f(x)$, applying a symplectic Runge-Kutta method and differentiating the system with respect to $x_0$ are commutative operations.
	Regardless of the order in which they are applied, we obtain a numerical flow map $\varPhi'_h(x_0)$ to the dynamical system $\frac{\mathrm{d}}{\mathrm{d}t}\varphi'_t(x_0) = f'(\varphi_t(x_0))\varphi'_t(x_0)$ on the analytical flow map.
\end{theorem}
\begin{proof}
% begin proof
\end{proof}

% symplectic RK methods preserving quadratic first integrals
% the commutative diagram result


\subsection{Example - A Model for Phonation}

This example is based on the primary model from ``Models for Phonation''.
A vocal cord is modelled by two stiffness-coupled masses, and their one-dimensional displacements are given by $u$ and $v$.
The governing equation for motion, from Newton's law, is
\begin{align*}
	\dfrac{\mathrm{d}^2 u}{\mathrm{d}t^2} &= 1 - u + \beta \left(1 - \dfrac{1}{u^2}\right) + \omega (v - u) \\
	\alpha \dfrac{\mathrm{d}^2 v}{\mathrm{d}t^2} &= \lambda(1 - v) + \beta \left(1 - \dfrac{1}{v^2}\right) + \omega (u - v) \\
\end{align*}
We first express this as a Hamiltonian problem. Denote $q_1 = u$, $q_2 = v$.
We define momentum $p_1 = \dot{q}_1$, $p_2 = \alpha \dot{q}_2$.
A Hamiltonian, obtained by integrating the system, is
\begin{equation*}
	H = \frac{1}{2} \left( p_1^2 + \frac{1}{\alpha} p_2^2 \right) + \frac{\omega}{2}(q_1 - q_2)^2 - F(q_1) - G(q_2)
\end{equation*}
where
\begin{align*}
	F(q_1) &= q_1 - \frac{1}{2}q_1^2 + \beta \left( q_1 + \frac{1}{q_1} \right) \\
	G(q_2) &= \lambda \left(q_2 - \frac{1}{2}q_2^2 \right) + \beta \left( q_2 + \frac{1}{q_2} \right). \\
\end{align*}
Therefore, in Hamiltonian variables the coupled ODEs can be expressed as
\begin{eqnarray*}
	\dot{q}_1 = p_1 & ~ & \dot{q}_2 = \frac{1}{\alpha} p_2 \\
	\dot{p_1} = F'(q_1) - \omega(q_1 - q_2) & ~ & \dot{p_2} = G'(q_2) - \omega(q_2 - q_1)
\end{eqnarray*}
%...












\section{Properties of Symplectic Methods}

\subsection{Backward Error Analysis}

When we perform numerical integration on a dynamical system given by $\dot{x} = f(x)$,
we obtain a numerical solution in the form of the iteration $x_{n+1} = \Phi_h(x_n)$,
where $\Phi$ is a method of our choice.
This is a numerical solution, which may converge to the exact solution as $h \rightarrow 0$,
but it is not exact.
In backward error analysis, we look at the problem from another perspective.
Instead of considering the closeness of our numerical solution to the system,
we think of the numerical solution as an exact solution to a perturbed problem,
and analyse the perturbation of this new problem to the original.

We want to find a modified equation $\dot{\tilde{x}} = f_h (\tilde{x})$ which is similar to $\dot{x} = f(x)$,
and which is exactly solved by the obtained numerical solution, i.e, $x_n = \tilde{x}(nh)$.
We expect the perturbed problem to be of the form
\begin{equation*}
	\dot{\tilde{x}} = f_h(\tilde{x}) = f(\tilde{x}) + h f_1(\tilde{x}) + h^2 f_2(\tilde{x}) + \mathellipsis,
\end{equation*}
namely as a polynomial expansion about the original problem. Important to note is that this series is not guaranteed to converge as $N \rightarrow \infty$.
Now consider the expansion of the perturbed problem as a Taylor series. Write
\begin{equation*}
	\tilde{x}(t+h) = \tilde{x}(t) + h \dot{\tilde{x}}(t) + \frac{h^2}{2} \ddot{\tilde{x}}(t) + \mathellipsis
\end{equation*}
which we can simplify using the definition of $\tilde{y}(t)$.
%finish this bit

\subsection{Local Error}

%this section should all be on error of symplectic methods,
% necessity of uniform step size,

\subsection{Examples of Error Control}

% error control on explicit method versus symplectic method - what is the cost




\appendix












\end{document}